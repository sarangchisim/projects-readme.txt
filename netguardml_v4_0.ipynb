{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdGFkDEmHcxbW6++xhDmlb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarangchisim/projects-readme.txt/blob/main/netguardml_v4_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UY-tmrCdsOe",
        "outputId": "35f78dce-9ef2-408a-d187-e76e29e906f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.48.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (3.0.3)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.0.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.26.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pandas numpy scikit-learn seaborn matplotlib xgboost\n",
        "streamlit_code = \"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "import plotly.express as px\n",
        "import xgboost as xgb\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Streamlit app configuration\n",
        "st.set_page_config(page_title=\"NetGuardML\", layout=\"wide\")\n",
        "st.title(\"NetGuardML - Intrusion Detection System\")\n",
        "\n",
        "# Initialize session state with default values\n",
        "def initialize_session_state():\n",
        "    if 'data' not in st.session_state:\n",
        "        st.session_state.data = None\n",
        "    if 'target_column' not in st.session_state:\n",
        "        st.session_state.target_column = None\n",
        "    if 'model' not in st.session_state:\n",
        "        st.session_state.model = None\n",
        "    if 'X_test' not in st.session_state:\n",
        "        st.session_state.X_test = None\n",
        "    if 'y_test' not in st.session_state:\n",
        "        st.session_state.y_test = None\n",
        "    if 'preprocessor' not in st.session_state:\n",
        "        st.session_state.preprocessor = None\n",
        "    if 'X_train_processed' not in st.session_state:\n",
        "        st.session_state.X_train_processed = None\n",
        "    if 'X_test_processed' not in st.session_state:\n",
        "        st.session_state.X_test_processed = None\n",
        "    if 'y_train' not in st.session_state:\n",
        "        st.session_state.y_train = None\n",
        "    if 'step' not in st.session_state:\n",
        "        st.session_state.step = 1\n",
        "\n",
        "initialize_session_state()\n",
        "\n",
        "# Reset session state to Step 1\n",
        "def reset_to_step_1():\n",
        "    st.session_state.data = None\n",
        "    st.session_state.target_column = None\n",
        "    st.session_state.model = None\n",
        "    st.session_state.X_test = None\n",
        "    st.session_state.y_test = None\n",
        "    st.session_state.preprocessor = None\n",
        "    st.session_state.X_train_processed = None\n",
        "    st.session_state.X_test_processed = None\n",
        "    st.session_state.y_train = None\n",
        "    st.session_state.step = 1\n",
        "\n",
        "# Navigation buttons\n",
        "def show_navigation_buttons():\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        if st.session_state.step > 1:\n",
        "            if st.button(\"One Step Back\"):\n",
        "                st.session_state.step -= 1\n",
        "                st.rerun()\n",
        "    with col2:\n",
        "        if st.session_state.step > 1:\n",
        "            if st.button(\"Reset to 1st Step\"):\n",
        "                reset_to_step_1()\n",
        "                st.rerun()\n",
        "\n",
        "# Step 1: Upload and preprocess data\n",
        "if st.session_state.step == 1:\n",
        "    st.header(\"Step 1: Upload and Preprocess Data\")\n",
        "    uploaded_file = st.file_uploader(\"Upload your CSV file\", type=[\"csv\"])\n",
        "    if uploaded_file is not None:\n",
        "        try:\n",
        "            st.session_state.data = pd.read_csv(uploaded_file)\n",
        "            st.write(\"Data Preview:\")\n",
        "            st.dataframe(st.session_state.data.head())\n",
        "            st.session_state.step = 2\n",
        "            st.rerun()\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error loading CSV file: {e}\")\n",
        "\n",
        "# Step 2: Select target and features\n",
        "if st.session_state.step == 2 and st.session_state.data is not None:\n",
        "    st.header(\"Step 2: Select Target and Features\")\n",
        "\n",
        "    # Display the dataset\n",
        "    st.subheader(\"Dataset Preview\")\n",
        "    st.dataframe(st.session_state.data, height=300)\n",
        "\n",
        "    # Select target column\n",
        "    columns = st.session_state.data.columns.tolist()\n",
        "    st.session_state.target_column = st.selectbox(\"Select Target Column\", columns,\n",
        "                                                 help=\"Choose the column to predict (e.g., xAttack)\")\n",
        "\n",
        "    # Select columns to drop (optional)\n",
        "    columns_to_drop = st.multiselect(\"Select columns to drop (optional)\",\n",
        "                                    [col for col in columns if col != st.session_state.target_column],\n",
        "                                    help=\"Optionally select columns to exclude from analysis\")\n",
        "\n",
        "    # Select columns to encode (optional)\n",
        "    encode_cols = st.multiselect(\"Select categorical columns to encode (optional)\",\n",
        "                                [col for col in columns if col != st.session_state.target_column and col not in columns_to_drop],\n",
        "                                help=\"Optionally select categorical columns for encoding (e.g., protocol_type, service, flag)\")\n",
        "\n",
        "    if st.button(\"Preprocess Data\"):\n",
        "        try:\n",
        "            # Prepare data\n",
        "            data = st.session_state.data.drop(columns=columns_to_drop, errors='ignore')\n",
        "            X = data.drop(columns=[st.session_state.target_column])\n",
        "            y = data[st.session_state.target_column]\n",
        "\n",
        "            # Define preprocessor\n",
        "            numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "            categorical_features = encode_cols if encode_cols else []\n",
        "\n",
        "            preprocessor = ColumnTransformer(\n",
        "                transformers=[\n",
        "                    ('num', Pipeline([\n",
        "                        ('imputer', SimpleImputer(strategy='mean')),\n",
        "                        ('scaler', StandardScaler())\n",
        "                    ]), numeric_features),\n",
        "                    ('cat', Pipeline([\n",
        "                        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "                        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "                    ]), categorical_features)\n",
        "                ])\n",
        "\n",
        "            # Split data\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "            # Fit preprocessor and transform data\n",
        "            X_train_processed = preprocessor.fit_transform(X_train)\n",
        "            X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "            # Store in session state\n",
        "            st.session_state.preprocessor = preprocessor\n",
        "            st.session_state.X_test = X_test\n",
        "            st.session_state.y_test = y_test\n",
        "            st.session_state.X_train_processed = X_train_processed\n",
        "            st.session_state.X_test_processed = X_test_processed\n",
        "            st.session_state.y_train = y_train\n",
        "\n",
        "            st.success(\"Data preprocessed successfully!\")\n",
        "            st.session_state.step = 3\n",
        "            st.rerun()\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error during preprocessing: {e}\")\n",
        "\n",
        "    show_navigation_buttons()\n",
        "\n",
        "# Step 3: Train models and visualize\n",
        "if st.session_state.step == 3 and 'X_train_processed' in st.session_state and st.session_state.X_train_processed is not None:\n",
        "    st.header(\"Step 3: Train Models and Visualize\")\n",
        "\n",
        "    # Model selection\n",
        "    model_choice = st.selectbox(\"Select Model\", [\"Random Forest\", \"XGBoost\", \"Logistic Regression\", \"Decision Tree\", \"SVM\", \"KNN\"])\n",
        "\n",
        "    # Clustering parameters\n",
        "    st.subheader(\"Clustering Analysis\")\n",
        "    n_clusters = st.slider(\"Select number of clusters\", min_value=2, max_value=10, value=4)\n",
        "\n",
        "    if st.button(\"Train Model and Perform Clustering\"):\n",
        "        try:\n",
        "            # Train selected model\n",
        "            if model_choice == \"Random Forest\":\n",
        "                model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "            elif model_choice == \"XGBoost\":\n",
        "                model = xgb.XGBClassifier(random_state=42)\n",
        "            elif model_choice == \"Logistic Regression\":\n",
        "                model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "            elif model_choice == \"Decision Tree\":\n",
        "                model = DecisionTreeClassifier(random_state=42)\n",
        "            elif model_choice == \"SVM\":\n",
        "                model = SVC(kernel='linear', random_state=42)\n",
        "            else:  # KNN\n",
        "                model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "            model.fit(st.session_state.X_train_processed, st.session_state.y_train)\n",
        "            st.session_state.model = model\n",
        "\n",
        "            # Evaluate model\n",
        "            y_pred = model.predict(st.session_state.X_test_processed)\n",
        "            accuracy = accuracy_score(st.session_state.y_test, y_pred)\n",
        "            precision = precision_score(st.session_state.y_test, y_pred, average='weighted')\n",
        "            recall = recall_score(st.session_state.y_test, y_pred, average='weighted')\n",
        "            f1 = f1_score(st.session_state.y_test, y_pred, average='weighted')\n",
        "\n",
        "            st.write(\"Model Performance:\")\n",
        "            st.write(f\"Accuracy: {accuracy:.4f}\")\n",
        "            st.write(f\"Precision: {precision:.4f}\")\n",
        "            st.write(f\"Recall: {recall:.4f}\")\n",
        "            st.write(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "            # Feature importance (for Random Forest and Decision Tree)\n",
        "            if model_choice in [\"Random Forest\", \"Decision Tree\"]:\n",
        "                feature_names = (st.session_state.preprocessor\n",
        "                                .named_transformers_['num'].named_steps['scaler']\n",
        "                                .get_feature_names_out().tolist() +\n",
        "                                st.session_state.preprocessor\n",
        "                                .named_transformers_['cat'].named_steps['onehot']\n",
        "                                .get_feature_names_out().tolist())\n",
        "                importance = model.feature_importances_\n",
        "                feature_importance = pd.DataFrame({'Feature': feature_names, 'Importance': importance})\n",
        "                feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
        "\n",
        "                fig, ax = plt.subplots()\n",
        "                sns.barplot(x='Importance', y='Feature', data=feature_importance.head(10))\n",
        "                st.pyplot(fig)\n",
        "\n",
        "            # Confusion matrix\n",
        "            cm = confusion_matrix(st.session_state.y_test, y_pred)\n",
        "            fig, ax = plt.subplots()\n",
        "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "            plt.xlabel('Predicted')\n",
        "            plt.ylabel('Actual')\n",
        "            st.pyplot(fig)\n",
        "\n",
        "            # Clustering\n",
        "            st.subheader(\"Clustering Results\")\n",
        "            kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "            cluster_labels = kmeans.fit_predict(st.session_state.X_train_processed)\n",
        "\n",
        "            # PCA for visualization\n",
        "            pca = PCA(n_components=2)\n",
        "            X_pca = pca.fit_transform(st.session_state.X_train_processed)\n",
        "\n",
        "            # Create DataFrame for plotting\n",
        "            plot_data = pd.DataFrame({\n",
        "                'PC1': X_pca[:, 0],\n",
        "                'PC2': X_pca[:, 1],\n",
        "                'Cluster': cluster_labels,\n",
        "                'Attack': st.session_state.y_train\n",
        "            })\n",
        "\n",
        "            # Plotly scatter plot\n",
        "            fig = px.scatter(plot_data, x='PC1', y='PC2', color='Attack',\n",
        "                            symbol='Cluster', title='K-Means Clustering with PCA',\n",
        "                            labels={'PC1': 'Principal Component 1', 'PC2': 'Principal Component 2'})\n",
        "            st.plotly_chart(fig)\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error during model training or clustering: {e}\")\n",
        "\n",
        "    # Next button to advance to Step 4\n",
        "    if st.button(\"Next\"):\n",
        "        st.session_state.step = 4\n",
        "        st.rerun()\n",
        "\n",
        "    show_navigation_buttons()\n",
        "\n",
        "# Step 4: Predict on new data\n",
        "if st.session_state.step == 4 and 'model' in st.session_state and st.session_state.model is not None:\n",
        "    st.header(\"Step 4: Predict on New Data\")\n",
        "    new_file = st.file_uploader(\"Upload new CSV for predictions\", type=[\"csv\"])\n",
        "\n",
        "    if new_file is not None:\n",
        "        try:\n",
        "            new_data = pd.read_csv(new_file)\n",
        "            if st.button(\"Predict\"):\n",
        "                # Ensure new data has same columns as training data (except target)\n",
        "                expected_columns = st.session_state.X_test.columns\n",
        "                if set(expected_columns).issubset(new_data.columns):\n",
        "                    new_data_processed = st.session_state.preprocessor.transform(new_data[expected_columns])\n",
        "                    predictions = st.session_state.model.predict(new_data_processed)\n",
        "\n",
        "                    # Add predictions to new data\n",
        "                    new_data['Predicted_Attack'] = predictions\n",
        "                    st.write(\"Predictions:\")\n",
        "                    st.write(new_data)\n",
        "\n",
        "                    # Download predictions\n",
        "                    csv = new_data.to_csv(index=False)\n",
        "                    st.download_button(\"Download Predictions\", csv, \"predictions.csv\", \"text/csv\")\n",
        "                else:\n",
        "                    st.error(\"New data must have the same columns as the training data (excluding target).\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error processing new data: {e}\")\n",
        "\n",
        "    show_navigation_buttons()\n",
        "\n",
        "st.write(\"____NetGuardML - By Team Z3r0___\")\n",
        "\"\"\"\n",
        "\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(streamlit_code)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78jiiFvufNx5",
        "outputId": "b2daf2af-9258-482a-e773-38df9524368b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.32.204.204:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0Kyour url is: https://yummy-lands-hope.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}